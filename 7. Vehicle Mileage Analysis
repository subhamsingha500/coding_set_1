//Scala_Spark

import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._

val spark = SparkSession.builder
  .appName("Mileage")
  .getOrCreate()

import spark.implicits._

val vehicles = List(
("CarA", 30),
("CarB", 22),
("CarC", 18),
("CarD", 15),
("CarE", 10),
("CarF", 28),
("CarG", 12),
("CarH", 35),
("CarI", 25),
("CarJ", 16)
).toDF("vehicle_name", "mileage")

val workdf = vehicles
  .withColumn("vehicle_name",initcap(col("vehicle_name")))
  .withColumn("Efficiency", 
    when(col("mileage")>25,"High Efficiency")
    .when(col("mileage").between(15,25),"Moderate Efficiency")
    .otherwise("Low Efficiency"))

workdf.show()


//Py_Spark

%python
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, when, initcap

spark = SparkSession.builder.appName("Mileage").getOrCreate()

vehicles = [
("CarA", 30),
("CarB", 22),
("CarC", 18),
("CarD", 15),
("CarE", 10),
("CarF", 28),
("CarG", 12),
("CarH", 35),
("CarI", 25),
("CarJ", 16)
]
vehicles_df = spark.createDataFrame(vehicles, ["vehicle_name", "mileage"])


workdf = vehicles_df \
  .withColumn("vehicle_name",initcap(col("vehicle_name"))) \
  .withColumn("Efficiency", 
    when(col("mileage")>25,"High Efficiency")
    .when(col("mileage").between(15,25),"Moderate Efficiency")
    .otherwise("Low Efficiency"))

workdf.show()
